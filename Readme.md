# ğŸ“œ RAG-Based Summarizer with QnA Chatbot

## ğŸš€ Overview
This project is an AI-powered **RAG-Based Summarizer** that can extract and summarize content from various sources, including:
- **YouTube Videos** (via transcription)
- **PDF Documents** (with text and image OCR extraction)
- **Websites**

It also features a **RAG-Based QnA Chatbot**, allowing users to ask questions based on the extracted text or summary.

Users can choose different **LLMs** for summarization and QnA, leveraging **Groq AI** with LangChain.

## ğŸ¯ Features
âœ… **Multi-source Summarization:** Extract and summarize text from YouTube, PDFs, and websites.  
âœ… **LLM Selection:** Choose from Llama-3-70B, Llama-3-8B, or Mixtral models.  
âœ… **OCR Support:** Extract text from images in PDFs.  
âœ… **RAG-Based QnA Chatbot:** Chat with either the extracted text or the summary.  
âœ… **ChromaDB Integration:** Stores vectorized text for retrieval-augmented generation.  
âœ… **Analytics Dashboard:** View summarization statistics, word count, and token usage.

---

## ğŸ› ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/your-repo-url.git
cd your-project-folder
```

### 2ï¸âƒ£ Create a Virtual Environment
```sh
python -m venv venv
source venv/bin/activate  # On macOS/Linux
venv\Scripts\activate    # On Windows
```

### 3ï¸âƒ£ Install Dependencies
```sh
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Up API Keys
Create a `.env` file and add your **Groq AI API Key**:
```
GROQ_API_KEY=your_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here
```

### 5ï¸âƒ£ Run the Streamlit App
```sh
streamlit run app.py
```

---

## ğŸ—ï¸ Project Structure
```
ğŸ“‚ project-folder/
â”‚â”€â”€ ğŸ“œ app.py                     # Streamlit UI
â”‚â”€â”€ ğŸ“‚ modules/                   # Core functionalities
â”‚   â”‚â”€â”€ summarizer.py             # Summarization logic
â”‚   â”‚â”€â”€ youtube_extractor.py      # Extract YouTube transcripts
â”‚   â”‚â”€â”€ pdf_extractor.py          # Extract text & images from PDFs
â”‚   â”‚â”€â”€ web_extractor.py          # Extract text from websites
â”‚   â”‚â”€â”€ qna_bot.py                # RAG-based QnA chatbot
â”‚   â”‚â”€â”€ vector_store.py           # ChromaDB vector storage
â”‚   â”‚â”€â”€ llm_manager.py            # LLM selection & invocation
â”‚â”€â”€ ğŸ“‚ data/                      # Stores processed text & vectors
â”‚â”€â”€ requirements.txt              # Dependencies
â”‚â”€â”€ README.md                     # Project documentation
```

---

## ğŸ“ Usage

### ğŸ”¹ Summarization
1ï¸âƒ£ Choose a source: **YouTube, PDF, or Website**.  
2ï¸âƒ£ Provide the **video URL, PDF file, or webpage URL**.  
3ï¸âƒ£ Select an **LLM** (Llama-3-70B, Llama-3-8B, Mixtral).  
4ï¸âƒ£ Click **Summarize** to generate a summary.

### ğŸ”¹ Chat with Extracted Text
1ï¸âƒ£ Select **"Chat with Extracted Text"** mode.  
2ï¸âƒ£ Ask questions about the original extracted content.

### ğŸ”¹ Chat with Summarized Content
1ï¸âƒ£ Select **"Chat with Summary"** mode.  
2ï¸âƒ£ Get answers based on the condensed summary.

---

## ğŸ”¥ Future Enhancements
- **Multi-document summarization**
- **Query-based summarization**
- **AI-generated key takeaways**
- **Voice input & AI speech response**
- **LLM cost & token estimation**

---

## ğŸ¤ Contributing
1. Fork the repo & create a new branch.  
2. Implement changes & commit with meaningful messages.  
3. Open a pull request & describe your changes.  

---

## ğŸ“œ License
This project is licensed under the **MIT License**. Feel free to modify and distribute it.

---


